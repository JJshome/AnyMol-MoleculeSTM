{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading for AnyMol-MoleculeSTM\n",
    "\n",
    "This notebook demonstrates how to load and preprocess molecular datasets for AnyMol-MoleculeSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "# Add parent directory to path\n",
    "module_path = os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), '../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Import AnyMol-MoleculeSTM modules\n",
    "from anymol.data.utils import (\n",
    "    load_smiles_from_file,\n",
    "    calculate_molecular_properties,\n",
    "    visualize_property_distribution,\n",
    "    visualize_molecule_grid,\n",
    "    preprocess_dataset\n",
    ")\n",
    "from anymol.data.dataset import MoleculeTokenizer, MoleculeDataset, MoleculeCollator\n",
    "from anymol.initialization import AnyMolSTMInitializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creating Datasets\n",
    "\n",
    "First, let's see how to create datasets using the provided script. We'll run the script in three different modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "os.makedirs('../../data/examples', exist_ok=True)\n",
    "\n",
    "# Display the command to run\n",
    "print(\"Command to create a custom dataset:\")\n",
    "print(\"python ../../examples/create_dataset.py --dataset_type custom --num_molecules 100 --output_dir ../../data/examples\")\n",
    "\n",
    "# Comment out the following line to actually run the command\n",
    "# !python ../../examples/create_dataset.py --dataset_type custom --num_molecules 100 --output_dir ../../data/examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using ChEMBL (requires internet connection and chembl_webresource_client)\n",
    "print(\"Command to create a ChEMBL dataset:\")\n",
    "print(\"python ../../examples/create_dataset.py --dataset_type chembl --num_molecules 100 --output_dir ../../data/examples\")\n",
    "\n",
    "# Comment out the following line to actually run the command\n",
    "# !python ../../examples/create_dataset.py --dataset_type chembl --num_molecules 100 --output_dir ../../data/examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using ZINC (requires internet connection)\n",
    "print(\"Command to create a ZINC dataset:\")\n",
    "print(\"python ../../examples/create_dataset.py --dataset_type zinc --num_molecules 100 --output_dir ../../data/examples\")\n",
    "\n",
    "# Comment out the following line to actually run the command\n",
    "# !python ../../examples/create_dataset.py --dataset_type zinc --num_molecules 100 --output_dir ../../data/examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating a Custom Dataset Programmatically\n",
    "\n",
    "Instead of using the script, we can create a dataset programmatically using the utility functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some example molecules (common drug molecules)\n",
    "smiles_list = [\n",
    "    \"CC(=O)OC1=CC=CC=C1C(=O)O\",  # Aspirin\n",
    "    \"CC(C)CC1=CC=C(C=C1)C(C)C(=O)O\",  # Ibuprofen\n",
    "    \"CN1C=NC2=C1C(=O)N(C(=O)N2C)C\",  # Caffeine\n",
    "    \"C1=CC=C2C(=C1)C=C(C=C2)CC3C(=O)NC(=O)S3\",  # A penicillin derivative\n",
    "    \"COC1=CC=C(C=C1)CCN(C)C\",  # Methamphetamine\n",
    "    \"CN1C=NC2=C1C(=O)N(C(=O)N2C)C\",  # Theophylline\n",
    "    \"CC(C)NCC(O)COC1=CC=CC2=C1C=CN2\",  # Propranolol\n",
    "    \"COC1=C(C=C(C=C1)CCN)OC\",  # 2,5-Dimethoxy-4-methylamphetamine\n",
    "    \"CC(=O)NCCCCCCCCCCN1C(=O)C2=CC=CC=C2NC1=O\",  # Capsaicin analog\n",
    "    \"COC1=CC(=C(C(=C1)OC)OC)CC=C\"  # Estragole\n",
    "]\n",
    "\n",
    "# Calculate molecular properties\n",
    "df = calculate_molecular_properties(smiles_list, property_names=[\"logP\", \"TPSA\", \"MolWt\", \"QED\"])\n",
    "\n",
    "# Display the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize property distribution\n",
    "visualize_property_distribution(df, property_names=[\"logP\", \"TPSA\", \"MolWt\", \"QED\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize molecules\n",
    "visualize_molecule_grid(df[\"SMILES\"].tolist(), n_cols=3, legends=[\n",
    "    \"Aspirin\", \"Ibuprofen\", \"Caffeine\", \"Penicillin\", \"Methamphetamine\", \n",
    "    \"Theophylline\", \"Propranolol\", \"DMMA\", \"Capsaicin analog\", \"Estragole\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataset\n",
    "output_file = '../../data/examples/custom_drugs.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"Saved dataset to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading Custom Datasets from Local Files\n",
    "\n",
    "You can also load your own datasets from local files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load molecules from a local file\n",
    "def load_local_dataset(input_file, output_file=None, smiles_column=\"SMILES\"):\n",
    "    \"\"\"Load molecules from a local file and preprocess them.\"\"\"\n",
    "    # Check file extension\n",
    "    file_extension = os.path.splitext(input_file)[1].lower()\n",
    "    \n",
    "    # Load SMILES from file\n",
    "    smiles_list = load_smiles_from_file(input_file, smiles_column=smiles_column)\n",
    "    \n",
    "    # Calculate properties\n",
    "    df = calculate_molecular_properties(smiles_list)\n",
    "    \n",
    "    # Save to output file if specified\n",
    "    if output_file:\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"Saved processed dataset to {output_file}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: load from the custom dataset we created earlier\n",
    "df_loaded = load_local_dataset('../../data/examples/custom_drugs.csv')\n",
    "df_loaded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating a MoleculeDataset for Training\n",
    "\n",
    "Now let's create a MoleculeDataset that can be used for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a tokenizer\n",
    "tokenizer = MoleculeTokenizer(max_length=100)\n",
    "\n",
    "# Build vocabulary from our SMILES\n",
    "tokenizer.build_vocab_from_smiles(df[\"SMILES\"].tolist())\n",
    "\n",
    "# Display vocabulary size\n",
    "print(f\"Vocabulary size: {len(tokenizer.token2idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a MoleculeDataset\n",
    "dataset = MoleculeDataset(\n",
    "    data_file='../../data/examples/custom_drugs.csv',\n",
    "    tokenizer=tokenizer,\n",
    "    property_names=[\"logP\", \"TPSA\", \"MolWt\", \"QED\"],\n",
    "    smiles_column=\"SMILES\",\n",
    "    max_length=100,\n",
    "    calculate_properties=False,  # Properties already calculated\n",
    ")\n",
    "\n",
    "# Check dataset size\n",
    "print(f\"Dataset size: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect an example from the dataset\n",
    "example = dataset[0]\n",
    "print(f\"SMILES: {example['smiles']}\")\n",
    "print(f\"Input IDs shape: {example['input_ids'].shape}\")\n",
    "print(f\"Attention mask shape: {example['attention_mask'].shape}\")\n",
    "print(f\"Properties: {example['properties']}\")\n",
    "\n",
    "# Decode the input IDs back to SMILES\n",
    "decoded = tokenizer.decode(example['input_ids'])\n",
    "print(f\"Decoded SMILES: {decoded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Using the AnyMolSTMInitializer\n",
    "\n",
    "Finally, let's use the AnyMolSTMInitializer to load data and initialize the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a configuration dictionary\n",
    "config = {\n",
    "    \"model\": {\n",
    "        \"embedding_dim\": 256,  # Smaller for this example\n",
    "        \"hidden_dim\": 128,\n",
    "        \"num_layers\": 2,\n",
    "        \"num_heads\": 4,\n",
    "        \"property_names\": [\"logP\", \"TPSA\", \"MolWt\", \"QED\"],\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"train_file\": '../../data/examples/custom_drugs.csv',\n",
    "        \"batch_size\": 2,\n",
    "        \"num_workers\": 0,  # For Jupyter notebook\n",
    "    }\n",
    "}\n",
    "\n",
    "# Initialize the system\n",
    "initializer = AnyMolSTMInitializer(config_dict=config)\n",
    "\n",
    "# Prepare datasets\n",
    "datasets = initializer.prepare_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "dataloaders = initializer.create_dataloaders()\n",
    "\n",
    "# Check dataloader\n",
    "print(f\"Number of batches in training dataloader: {len(dataloaders['train'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model (this will be very quick in this example since we're using a small model)\n",
    "# Note: In a real application, you would use the default model size\n",
    "model = initializer.initialize_model(device=\"cpu\")\n",
    "\n",
    "# Print model structure\n",
    "print(f\"Model initialized with {sum(p.numel() for p in model.parameters())} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualizing the Dataset\n",
    "\n",
    "Let's visualize some molecules from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample molecules from the dataset\n",
    "initializer.visualize_sample_molecules(dataset_key=\"train\", num_samples=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize property distributions\n",
    "initializer.visualize_dataset_properties(dataset_key=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we've demonstrated how to:\n",
    "\n",
    "1. Create datasets using the provided script\n",
    "2. Create custom datasets programmatically\n",
    "3. Load datasets from local files\n",
    "4. Create a MoleculeDataset and tokenizer\n",
    "5. Use the AnyMolSTMInitializer to streamline the process\n",
    "6. Visualize molecules and property distributions\n",
    "\n",
    "These methods can be extended to work with larger and more complex datasets as needed for your specific application."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
